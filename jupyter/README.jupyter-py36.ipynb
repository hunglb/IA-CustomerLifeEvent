{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Industry Accelerators - Life Event Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The Customer Life Event Prediction accelerator includes a structured glossary of more than 100 business terms and a set of sample data science assets. The glossary provides the information architecture that you need to predict major life events, such as buying a home or relocating. Your data scientists can use the sample notebooks, predictive models, and dashboards to accelerate data preparation, machine learning modeling, and data reporting. Set your clients on the path to financial success by engaging with them at the right time with relevant investment options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img src=\"../misc/images/acceleratorWorkflow.png\" alt=\"Service details\" style=\"height: 500px;\" align=\"center\" />\n",
    "    <br style=\"clear: both;\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventory of Artifacts provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Catalog\n",
    "\n",
    "Described in the Knowledge Center  https://www.ibm.com/support/knowledgecenter/en/SSQNUZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Datasets\n",
    "\n",
    "The sample input datasets are \n",
    "\n",
    "* **‘events.csv’** : Event data, Temporal data.\n",
    "* **'event_type.csv'** : Event Type Data, Life Event Category etc. \n",
    "* **'customer.csv'** : Customer Data, Demographic data. \n",
    "\n",
    "The idea is to generate a dataset which is used as input for model training and scoring purposes. \n",
    "\n",
    "Given a list of events which the customers experienced, the script transforms this long form dataset into a wide format with one record per customer, which can be used for modelling. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data fields used for the final dataset are described below:\n",
    "\n",
    "* **CUSTOMER_ID**: A unique ID for each customer in the dataset.\n",
    "* **EVENT_DATE**: Date that the event occurred. \n",
    "* **EVENT_TYPE_ID**: ID of event experienced by the customer. This field contains all events that occurred, for example, website logins, as well as any life events.\n",
    "\n",
    "<p>\n",
    "    <img src=\"../misc/images/event_table.png\" alt=\"Environment\" style=\"height: 65px;\" align=\"center\" />\n",
    "    <br style=\"clear: both;\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "\n",
    "* **0-data-import** : Connect to a DB2 database, read data from a number of tables, normalize, merge and output data to a CSV file for processing in the next step. This is an optional step - if you prefer to work with the sample CSV data provided with the project, you can skip this step. \n",
    "* **1-model-train**: Load data, prepare and clean data for model training, select life events to predict, build ML models, visualize data, select best performing ML model and save to ICP4D.\n",
    "* **2-model-score** : Operationalize the models, test the scoring pipeline as a Web Service, release and deploy Model Scoring REST API Endpoint, release the project, deploy scoring pipeline as a Webservice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts\n",
    "\n",
    "The following scripts are called from the notebooks mentioned above : \n",
    "\n",
    "* **life_event_prep.py** : Called from 1-model-train notebook. The script carries out the Data Preparation. Ensures that the final dataset contains one record per customer, with variables based on counts of the number of events that a customer had within a specified timeframe, (the observation window). The dataset contains a column for each event that occurred. The dataset also contains a target variable indicating whether that customer experienced the life event or not within a particular timeframe, (the forecast horizon).\n",
    "\n",
    "* **LFE_Scoring_Pipeline.py** : Called from 2-model-score. Loads models for each event type, Executes the model scoring and generates the predictions for the life events, Extracts the highest impact features and collaborates data to be used for the dashboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R - Studio\n",
    "\n",
    "* **Dashboard View** : Shows client activity, Top action Clients Market Action and Revenue Opportunities . Provides Search option to get client activity based on Customer ID. \n",
    "* **Client View** : Targets individual Client information, Depicts the Top Business Metrics, Visualizes Event distribution, Provides option to run the Model Scoring Webservice, Predicts Life Events and Visualizes the influential factors and data fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence of steps to run -- \n",
    "\n",
    "* Click notebooks, open 0-data-import & execute step-by-step (Optional)\n",
    "* Click notebooks, open 1-model-train & execute step-by-step\n",
    "* Click notebooks, open 2-model-score & execute step-by-step\n",
    "* Click RStudio, under the **Shiny** sub group click on LifeEventPredictionDashboard. In RStudio, navigate to the sub-folder LifeEventPredictionDashboard, open app.R and run the Shiny app by clicking on Run App button\n",
    "                                                  **OR**\n",
    "  If you deployed the app from the asset tab then Launch the dashboard by clicking on the shiny Dashboard under deployments tab in the Project Release    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This project contains Sample Materials, provided under license.\n",
    "<br>\n",
    "Licensed Materials - Property of IBM. <br>\n",
    "© Copyright IBM Corp. 2019. All Rights Reserved. <br>\n",
    "US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.<br>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
